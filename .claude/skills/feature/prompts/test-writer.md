# Test Writer Subagent

You are writing and running tests for a feature in the Fullmind Territory Planner. The project uses Vitest with jsdom environment, globals enabled, and Testing Library for React components.

## PRD

Read the PRD at: `{{PRD_PATH}}`

## What Was Implemented

{{IMPLEMENTER_REPORT}}

## Your Job

Write comprehensive tests for all new code, then run the full test suite to verify nothing is broken.

### Before Writing Tests

1. Read the implemented code (all files listed in the implementer report)
2. Read 2-3 existing test files near the implemented code to match conventions:
   - Tests live in `__tests__/` directories alongside implementation
   - Use `describe` and `it` blocks (Vitest style)
   - Import from `vitest`: `{ describe, it, expect, vi, beforeEach }`
   - For React components: `import { render, screen } from '@testing-library/react'`
3. Read the PRD's testing strategy section

### Test Conventions

```typescript
import { describe, it, expect } from "vitest";
// For React components:
// import { render, screen } from '@testing-library/react';

describe("FunctionOrComponent", () => {
  it("does specific thing when given specific input", () => {
    // Arrange
    const input = ...;

    // Act
    const result = functionUnderTest(input);

    // Assert
    expect(result).toBe(expectedValue);
  });
});
```

**Rules:**
- Test behavior, not implementation details
- Each `it` block tests one thing
- Descriptive test names that read as sentences
- No mocking unless absolutely necessary (prefer real implementations)
- Cover: happy path, edge cases, error cases
- For API routes: test request/response shapes
- For UI: test user interactions, not internal state

### What to Test

Based on the PRD testing strategy:
- **Unit tests**: Pure functions, data transformations, utility functions
- **Integration tests**: API routes (request -> response), store actions
- **Component tests**: User interactions, conditional rendering, error states

### Running Tests

After writing tests:

```bash
npx vitest run
```

Verify:
1. All new tests pass
2. All existing tests still pass
3. No test is skipped or marked `.todo`

### Output Format

```
## Test Results

**New tests written:** N tests across M files
**Test files:**
- `path/to/__tests__/file.test.ts` (N tests)
- ...

**Full suite results:**
- Total: N tests
- Passed: N
- Failed: N (if any â€” list them with error messages)

**Coverage notes:**
- [What's well covered]
- [What's not covered and why]
```

## Report

Report:
- Test files created (with paths)
- Number of tests written
- Full test suite pass/fail result
- If failures: exact error messages and which tests failed
- Any areas that couldn't be easily tested and why
